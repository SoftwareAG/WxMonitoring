input {
  beats {
    port => "${LOGSTASH_PORT:5044}"
	client_inactivity_timeout => 3600
  }
  http {
    port => "${LOGSTASH_HTTP_IMPORT_PORT:5045}"
  }
}

filter {
	if [agent][version] =~ "^7" {
		mutate{
				add_field => { 
							offset => "%{[log][offset]}" 
							source => "%{[log][file][path]}"
							host => "%{[host][name]}" 
							filebeat_timezone1 => "%{[event][timezone]}" 
						}
				remove_field => [ "log", "agent", "input", "host","event","ecs"]
		}
	} else{
		mutate{
				add_field => { 
							filebeat_timezone1 => "%{[beat][timezone]}"  
						}
		}
	}
	if !("" in [filebeat_timezone1]){
		mutate {
			add_field => { 
				filebeat_timezone => "Europe/Berlin"  
			}
			remove_field => ["filebeat_timezone1"]
		}
	} else {
		translate {
			field => "filebeat_timezone1"
			destination => "filebeat_timezone"
			dictionary => {
				"MDT" => "MST "
				"EDT" => "EST"
				"BST" => "GMT"
				"WEST" => "WET"
				"CEST" => "CET"
				"EEST" => "EET"
				"ACDT" => "ACT"
			}
			remove_field => "filebeat_timezone1"
		}
	}
	if [log_identifier] == "server_log"{
		grok {
			match => { "message" => "%{TIMESTAMP_ISO8601:event_timestamp} %{WORD:log_time_zone} \[%{DATA:event_code}(?<severity>.)\] %{GREEDYDATA:event_information}" 
					}
			add_field => { "event_identifier" => "unknown_IS_event" }
		}
		
		#convert event_timestamp to date type.
	
		date {
			match => [ "event_timestamp", "yyyy-MM-dd HH:mm:ss" ]
			timezone => "Europe/Berlin"
			target => ["event_timestamp_in_utc"]
		}

		mutate {
			replace => { "event_timestamp" => " %{event_timestamp_in_utc}" }
			gsub => [
						"event_timestamp", "T", " ",
						"event_timestamp", ".000Z", ""
					]
			strip => ["event_timestamp"]
			remove_field => [ "event_timestamp_in_utc"]
		}

		date {
			match => [ "event_timestamp_utc", "yyyy-MM-dd HH:mm:ss" ]
		}
		
		grok {
				match => { "event_code" => "^%{DATA:event_tags}\..*$" }
			}
		
		if [event_code] =~ "^BPM.0102" {
			if [event_code] !~ "^BPM.0102.0002" {
				mutate {
					# Renames the 'log_identifier' field to 'server_process_log'
					replace  => { "log_identifier" => "server_process_log" }
				}
				clone {
					clones => [ "process_log" ]
				}
			}
		}
		
		if [type] == "process_log"{
			if [log_identifier] == "server_process_log" {
				if [severity] == 'I' or [severity] == 'E' {
					mutate {
						# Renames the 'log_identifier' field to 'server_process_log_known'
						replace  => { "log_identifier" => "server_process_log_known" }
					}
					if [severity] == 'I' {
						grok {
							match => { "event_information" => "%{UUID:process_id}\:(?<process_instance>.)\,\ MID\=%{WORD:business_domain}\/%{WORD:process_name}\,\ MVer\=%{WORD:MVer}: %{GREEDYDATA:process_message}" }
						}

						if[process_message] =~ 'process started'{
							mutate{
								add_field => { started_timestamp_utc => "%{[event_timestamp]}"
												current_status => "started"}
							}
						} else if[process_message] =~ 'process completed' {
							mutate{
								add_field => { completed_timestamp_utc => "%{[event_timestamp]}" 
												current_status => "completed"}
							}
						} else if[process_message] =~ 'process failed' {
							mutate{
								add_field => { failed_timestamp_utc => "%{[event_timestamp]}" 
												current_status => "failed"}
							}
						}
							else if[process_message] =~ 'process cancelled' {
							mutate{
								add_field => { cancelled_timestamp_utc => "%{[event_timestamp]}" 
												current_status => "cancelled"}
							}
						}else{
							grok {
								match => { "event_information" => "%{GREEDYDATA:log_before_process_id}%{UUID:process_id}%{GREEDYDATA:log_after_process_id}" }
							}	
							mutate {
								# Renames the 'log_identifier' field to 'custom_log_event'
								replace  => { "log_identifier" => "server_process_log_unknown" }
							}
						}
						
					} else {
						grok {
							match => { "event_information" => "%{UUID:process_id}\:(?<process_instance>.)\,\ %{WORD:step_id}\:%{GREEDYDATA:exception_message}" }
						}
						
						if !("" in [exception_message]) {
							grok {
								match => { "event_information" => "%{GREEDYDATA:log_before_process_id}%{UUID:process_id}%{GREEDYDATA:log_after_process_id}" }
							}
							mutate {
								# Renames the 'log_identifier' field to 'custom_log_event'
								replace  => { "log_identifier" => "server_process_log_unknown" }
							}
						} else {
							mutate{
								add_field => { exception_timestamp_utc => "%{[event_timestamp]}" 
												current_status => "exception"}
							}
						}
					}
				} else {
					grok {
							match => { "event_information" => "%{GREEDYDATA:log_before_process_id}%{UUID:process_id}%{GREEDYDATA:log_after_process_id}" }
						}
					mutate {
						# Renames the 'log_identifier' field to 'custom_log_event'
						replace  => { "log_identifier" => "server_process_log_unknown" }
					}
				}
			}
			if ("" in [process_id]) {
				mutate {
					add_field => { 
						log_id => "%{process_id}"
						last_updated_utc => "%{event_timestamp}"
						log_history => "%{message}"
						process_env => "%{[fields][env]}"
					}
					remove_field => [ "time_zone", "@version", "host", "event_code", "severity", "event_information", "message", "log_after_process_id", "log_before_process_id", "beat", "prospector", "event_identifier", "fields", "tags", "event_timestamp", "headers"]
				}
			} else { 
				drop {}
			}
		} else{
		
			mutate {
				add_field => { event_env => "%{[fields][env]}" }
				rename  => { "message" => "complete_event_log" }
				rename => { "event_timestamp" => "event_timestamp_utc" }
				remove_field => ["time_zone", "beat", "prospector", "tags", "fields", "@version", "log_filePath", "headers" ]
			}
	 
			translate {
				field => "severity"
				destination => "event_severity"
				dictionary => {
					"D" => "DEBUG"
					"I" => "INFO"
					"E" => "ERROR"
					"C" => "FATAL"
					"W" => "WARNING"
				}
				remove_field => "severity"
			}
		}	
	} else if [log_identifier] == "wrapper_log" {
		grok {
			match => { "message" => "^%{DATA:event_severity}\|%{DATA:event_code}\|%{DATA:event_timestamp}\|%{GREEDYDATA:event_information}$" }
			add_field => { "event_identifier" => "unknown_wrapper_event" }
		}
		mutate {
			strip => ["event_severity", "event_code", "event_timestamp", "event_information"]
			gsub => ["event_timestamp", "/", "-"]
		}

		#convert event_timestamp to date type and in utc.
	
		date {
			match => [ "event_timestamp", "yyyy-MM-dd HH:mm:ss" ]
			timezone => "Europe/Berlin"
			target => ["event_timestamp_in_utc"]
		}

		mutate {
			replace => { "event_timestamp" => " %{event_timestamp_in_utc}" }
			gsub => [
						"event_timestamp", "T", " ",
						"event_timestamp", ".000Z", ""
					]
			strip => ["event_timestamp"]
			remove_field => [ "event_timestamp_in_utc"]
		}

		date {
			match => [ "event_timestamp_utc", "yyyy-MM-dd HH:mm:ss" ]
		}
		
		mutate {
			add_field => { 
							event_env => "%{[fields][env]}" 
							event_tags => "%{[event_code]}" 
						}
			rename  => { "message" => "complete_event_log" }
			rename => { "event_timestamp" => "event_timestamp_utc" }
			rename  => { "[beat][time_zone]" => "log_time_zone" }
			remove_field => ["time_zone", "beat", "prospector", "tags", "fields", "@version", "log_filePath", "headers" ]
			}
		
		if [event_severity] == "STATUS"{
			mutate {
				replace  => { "event_severity" => "INFO" }
			}
		}
	} else if [log_identifier] =~ "custom_" {
		
	} else {
		drop{}
	}
}

output {
	if [type] == 'process_log' {
		elasticsearch {
			hosts => ["${ELASTIC_SEARCH_ADDRESS:localhost:9200}"]
			user => ["${ELASTIC_SEARCH_LOGSTASH_USER}"]
			password => ["${ELASTIC_SEARCH_LOGSTASH_PASSWORD}"]
			index => "wxmonitoring-processes"
			document_id => "%{log_id}"
			action => "update"
			script => 'ctx._source.offset = params.event.get("offset");ctx._source.process_env = params.event.get("process_env");ctx._source.source = params.event.get("source");if (ctx._source.containsKey("log_history")) { ctx._source.log_history.add(params.event.get("log_history")) } else { ctx._source.log_history = [params.event.get("log_history")] }ctx._source.process_id = params.event.get("process_id"); if (ctx._source.last_updated_utc!=null){long currentLastUpdated = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(ctx._source.last_updated_utc).getTime();long newLastUpdated = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(params.event.get("last_updated_utc")).getTime();if (currentLastUpdated < newLastUpdated){ctx._source.last_updated_utc = params.event.get("last_updated_utc");} } else{ctx._source.last_updated_utc = params.event.get("last_updated_utc");} if (params.event.get("log_identifier") == "server_process_log_known"){ctx._source.process_instance = params.event.get("process_instance");if (params.event.get("current_status") == "exception"){ctx._source.current_status = params.event.get("current_status");} else if(params.event.get("current_status") == "started"){if (ctx._source.current_status == null){ctx._source.current_status = params.event.get("current_status");}}else{ctx._source.current_status = params.event.get("current_status");} if (params.event.get("current_status") == "exception") { if (ctx._source.containsKey("step_id")) { ctx._source.step_id.add(params.event.get("step_id")) } else { ctx._source.step_id = [params.event.get("step_id")] } if (ctx._source.containsKey("exception_timestamp_utc")) { ctx._source.exception_timestamp_utc.add(params.event.get("exception_timestamp_utc")) } else { ctx._source.exception_timestamp_utc = [params.event.get("exception_timestamp_utc")] } if (ctx._source.containsKey("exception_message")) { ctx._source.exception_message.add(params.event.get("exception_message")) } else { ctx._source.exception_message = [params.event.get("exception_message")] }} else { ctx._source.business_domain = params.event.get("business_domain"); ctx._source.process_name = params.event.get("process_name"); ctx._source.MVer = params.event.get("MVer"); if (params.event.get("current_status") == "started") { ctx._source.started_timestamp_utc = params.event.get("started_timestamp_utc"); } else if (params.event.get("current_status") == "completed") { ctx._source.completed_timestamp_utc = params.event.get("completed_timestamp_utc"); } else if (params.event.get("current_status") == "failed") { ctx._source.failed_timestamp_utc = params.event.get("failed_timestamp_utc"); } else { ctx._source.cancelled_timestamp_utc = params.event.get("cancelled_timestamp_utc"); }}}if (ctx._source.containsKey("event_tags")) { ctx._source.event_tags.add(params.event.get("event_tags")) } else { ctx._source.event_tags = [params.event.get("event_tags")] }'
			scripted_upsert => true	
		}
			
		elasticsearch {
			hosts => ["${ELASTIC_SEARCH_ADDRESS:localhost:9200}"]
			user => ["${ELASTIC_SEARCH_LOGSTASH_USER}"]
			password => ["${ELASTIC_SEARCH_LOGSTASH_PASSWORD}"]
			index => "wxmonitoring-processes-original"
			document_id => "%{log_id}"
			action => "update"
			script => 'ctx._source.offset = params.event.get("offset");ctx._source.process_env = params.event.get("process_env");ctx._source.source = params.event.get("source");if (ctx._source.containsKey("log_history")) { ctx._source.log_history.add(params.event.get("log_history")) } else { ctx._source.log_history = [params.event.get("log_history")] }ctx._source.process_id = params.event.get("process_id"); if (ctx._source.last_updated_utc!=null){long currentLastUpdated = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(ctx._source.last_updated_utc).getTime();long newLastUpdated = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss").parse(params.event.get("last_updated_utc")).getTime();if (currentLastUpdated < newLastUpdated){ctx._source.last_updated_utc = params.event.get("last_updated_utc");} } else{ctx._source.last_updated_utc = params.event.get("last_updated_utc");} if (params.event.get("log_identifier") == "server_process_log_known"){ctx._source.process_instance = params.event.get("process_instance");if (params.event.get("current_status") == "exception"){ctx._source.current_status = params.event.get("current_status");} else if(params.event.get("current_status") == "started"){if (ctx._source.current_status == null){ctx._source.current_status = params.event.get("current_status");}}else{ctx._source.current_status = params.event.get("current_status");} if (params.event.get("current_status") == "exception") { if (ctx._source.containsKey("step_id")) { ctx._source.step_id.add(params.event.get("step_id")) } else { ctx._source.step_id = [params.event.get("step_id")] } if (ctx._source.containsKey("exception_timestamp_utc")) { ctx._source.exception_timestamp_utc.add(params.event.get("exception_timestamp_utc")) } else { ctx._source.exception_timestamp_utc = [params.event.get("exception_timestamp_utc")] } if (ctx._source.containsKey("exception_message")) { ctx._source.exception_message.add(params.event.get("exception_message")) } else { ctx._source.exception_message = [params.event.get("exception_message")] }} else { ctx._source.business_domain = params.event.get("business_domain"); ctx._source.process_name = params.event.get("process_name"); ctx._source.MVer = params.event.get("MVer"); if (params.event.get("current_status") == "started") { ctx._source.started_timestamp_utc = params.event.get("started_timestamp_utc"); } else if (params.event.get("current_status") == "completed") { ctx._source.completed_timestamp_utc = params.event.get("completed_timestamp_utc"); } else if (params.event.get("current_status") == "failed") { ctx._source.failed_timestamp_utc = params.event.get("failed_timestamp_utc"); } else { ctx._source.cancelled_timestamp_utc = params.event.get("cancelled_timestamp_utc"); }}}if (ctx._source.containsKey("event_tags")) { ctx._source.event_tags.add(params.event.get("event_tags")) } else { ctx._source.event_tags = [params.event.get("event_tags")] }'
			scripted_upsert => true		
		}
	} else {
		elasticsearch {
			hosts => ["${ELASTIC_SEARCH_ADDRESS:localhost:9200}"]
			user => ["${ELASTIC_SEARCH_LOGSTASH_USER}"]
			password => ["${ELASTIC_SEARCH_LOGSTASH_PASSWORD}"]
			index => "wxmonitoring-events-%{+YYYY.MM.dd}"
		}
		elasticsearch {
			hosts => ["${ELASTIC_SEARCH_ADDRESS:localhost:9200}"]
			user => ["${ELASTIC_SEARCH_LOGSTASH_USER}"]
			password => ["${ELASTIC_SEARCH_LOGSTASH_PASSWORD}"]
			index => "wxmonitoring-events-original"
		}
	}
	stdout { codec => rubydebug }	
	file {
		path => "./logstash-dump-%{+YYYY-MM-dd}.txt"
  }
}

